{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import amrlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ::snt This is a test of the system.\n",
      "(t / test-01\n",
      "      :ARG1 (s / system)\n",
      "      :domain (t2 / this))\n",
      "# ::snt This is a second sentence.\n",
      "(s / sentence\n",
      "      :ord (o / ordinal-entity\n",
      "            :value 2)\n",
      "      :domain (t / this))\n"
     ]
    }
   ],
   "source": [
    "stog = amrlib.load_stog_model()\n",
    "graphs = stog.parse_sents(['This is a test of the system.', 'This is a second sentence.'])\n",
    "for graph in graphs:\n",
    "    print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gtos \u001b[38;5;241m=\u001b[39m \u001b[43mamrlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_gtos_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m sents, _ \u001b[38;5;241m=\u001b[39m gtos\u001b[38;5;241m.\u001b[39mgenerate(graphs)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sents:\n",
      "File \u001b[1;32mc:\\Users\\stoic\\miniconda3\\envs\\llms_env\\lib\\site-packages\\amrlib\\__init__.py:43\u001b[0m, in \u001b[0;36mload_gtos_model\u001b[1;34m(model_dir, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m gtos_model\n\u001b[0;32m     42\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m model_dir \u001b[38;5;28;01mif\u001b[39;00m model_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(defaults\u001b[38;5;241m.\u001b[39mdata_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_gtos\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m gtos_model \u001b[38;5;241m=\u001b[39m load_inference_model(model_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gtos_model\n",
      "File \u001b[1;32mc:\\Users\\stoic\\miniconda3\\envs\\llms_env\\lib\\site-packages\\amrlib\\models\\model_factory.py:75\u001b[0m, in \u001b[0;36mload_inference_model\u001b[1;34m(model_directory, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m'\u001b[39m, {})   \u001b[38;5;66;03m# get any model kwargs from the meta-data\u001b[39;00m\n\u001b[0;32m     74\u001b[0m model_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)             \u001b[38;5;66;03m# override them with amything passed in\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m model \u001b[38;5;241m=\u001b[39m model_class(model_directory, meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_fn\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\stoic\\miniconda3\\envs\\llms_env\\lib\\site-packages\\amrlib\\models\\generate_xfm\\inference.py:25\u001b[0m, in \u001b[0;36mInference.__init__\u001b[1;34m(self, model_dir, model_fn, model, tokenizer, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m default_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     24\u001b[0m device \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m, default_device)\n\u001b[1;32m---> 25\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtask_specific_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslation_amr_to_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Load the tokenizer. If kwargs passes in tok_name_or_path use that otherwise get from the config\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stoic\\miniconda3\\envs\\llms_env\\lib\\site-packages\\transformers\\modeling_utils.py:3110\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3109\u001b[0m         )\n\u001b[1;32m-> 3110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\stoic\\miniconda3\\envs\\llms_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stoic\\miniconda3\\envs\\llms_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stoic\\miniconda3\\envs\\llms_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 900 (4 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\stoic\\miniconda3\\envs\\llms_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stoic\\miniconda3\\envs\\llms_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stoic\\miniconda3\\envs\\llms_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gtos = amrlib.load_gtos_model()\n",
    "sents, _ = gtos.generate(graphs)\n",
    "for sent in sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ::snt This is a test of the SpaCy extension.\n",
      "(t / test-01\n",
      "      :ARG1 (e / extend-01\n",
      "            :ARG1 (p / product\n",
      "                  :name (n / name\n",
      "                        :op1 \"SpaCy\")))\n",
      "      :domain (t2 / this))\n",
      "# ::snt The test has multiple sentences.\n",
      "(h / have-03\n",
      "      :ARG0 (t / test)\n",
      "      :ARG1 (s / sentence\n",
      "            :quant (m / multiple)))\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "amrlib.setup_spacy_extension()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('This is a test of the SpaCy extension. The test has multiple sentences.')\n",
    "graphs = doc._.to_amr()\n",
    "for graph in graphs:\n",
    "    print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import amrlib\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "amrlib.setup_spacy_extension()\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your JSONL file\n",
    "file_path = \"data/massive_amr.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSONL file\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = [json.loads(line) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences and AMR graphs\n",
    "sentences = [entry[\"utt\"] for entry in data]\n",
    "amr_graphs = [entry[\"raw_amr\"] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### STOG: Sentences to AMR ###\n",
      "\n",
      "Sentence: what are some updates about the stock market\n",
      "AMR Graph:\n",
      "# ::snt what are some updates about the stock market\n",
      "(u / update-02\n",
      "      :ARG1 (m / market\n",
      "            :mod (s / stock))\n",
      "      :ARG2 (a / amr-unknown)\n",
      "      :quant (s2 / some))\n",
      "\n",
      "Sentence: definition of velocity\n",
      "AMR Graph:\n",
      "# ::snt definition of velocity\n",
      "(d / define-01\n",
      "      :ARG1 (v / velocity))\n",
      "\n",
      "Sentence: please look up exchange between us and mexico\n",
      "AMR Graph:\n",
      "# ::snt please look up exchange between us and mexico\n",
      "(l / look-up-05\n",
      "      :polite +\n",
      "      :mode imperative\n",
      "      :ARG0 (y / you)\n",
      "      :ARG1 (e / exchange-01\n",
      "            :ARG0 (w / we)\n",
      "            :ARG2 (c / country\n",
      "                  :name (n / name\n",
      "                        :op1 \"Mexico\"))))\n",
      "\n",
      "Sentence: can you describe to me what a pineapple looks like\n",
      "AMR Graph:\n",
      "# ::snt can you describe to me what a pineapple looks like\n",
      "(p / possible-01\n",
      "      :polarity (a / amr-unknown)\n",
      "      :ARG1 (d / describe-01\n",
      "            :ARG0 (y / you)\n",
      "            :ARG1 (l / look-02\n",
      "                  :ARG0 (p2 / pineapple)\n",
      "                  :ARG1 (t / thing))\n",
      "            :ARG2 (ii / i)))\n",
      "\n",
      "Sentence: what is the dollar against the pound\n",
      "AMR Graph:\n",
      "# ::snt what is the dollar against the pound\n",
      "(d / dollar\n",
      "      :prep-against (p / pound)\n",
      "      :domain (a / amr-unknown))\n"
     ]
    }
   ],
   "source": [
    "# --- Test STOG: Convert Sentences to AMR ---\n",
    "print(\"\\n### STOG: Sentences to AMR ###\")\n",
    "parsed_graphs = stog.parse_sents(sentences[:5])  # Test on first 5 sentences\n",
    "for sent, graph in zip(sentences[:5], parsed_graphs):\n",
    "    print(f\"\\nSentence: {sent}\\nAMR Graph:\\n{graph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### GTOS: AMR to Sentences ###\n",
      "\n",
      "AMR:\n",
      "(u / update-02\n",
      "      :ARG2 (a / amr-unknown)\n",
      "      :topic (m / market-01\n",
      "            :ARG1 (s / stock))\n",
      "      :mod (s2 / some))\n",
      "Reconstructed Sentence: What are some stock market updates?\n",
      "\n",
      "AMR:\n",
      "(d / define-01\n",
      "      :ARG1 (v / velocity)\n",
      "      :ARG2 (a / amr-unknown))\n",
      "Reconstructed Sentence: What is the definition of velocity?\n",
      "\n",
      "AMR:\n",
      "(l / look-up-05 :mode imperative :polite +\n",
      "      :ARG0 (y / you)\n",
      "      :ARG1 (e / exchange-01\n",
      "            :ARG1 (c / currency\n",
      "                  :mod (c3 / country :name (n / name :op1 \"us\")))\n",
      "            :ARG3 (c2 / currency\n",
      "                  :mod (c4 / country :name (n2 / name :op1 \"mexico\")))))\n",
      "Reconstructed Sentence: Please look up exchange rates between US and Mexican currency.\n",
      "\n",
      "AMR:\n",
      "(d / describe-01 :mode imperative :polite +\n",
      "      :ARG0 (y / you)\n",
      "      :ARG1 (t / thing\n",
      "            :ARG1-of (l / look-02\n",
      "                  :ARG0 (f / food-dish :name (n / name :op1 \"pineapple\")))))\n",
      "Reconstructed Sentence: Please describe how the pineapple looks.\n",
      "\n",
      "AMR:\n",
      "(h / have-quant-91\n",
      "      :ARG1 (c / currency :name (n / name :op1 \"dollar\"))\n",
      "      :ARG2 (a / amr-unknown)\n",
      "      :ARG4 (c2 / currency :name (n2 / name :op1 \"pound\")))\n",
      "Reconstructed Sentence: How many are dollars compared to pounds?\n"
     ]
    }
   ],
   "source": [
    "# --- Test GTOS: Convert AMR to Sentences ---\n",
    "print(\"\\n### GTOS: AMR to Sentences ###\")\n",
    "reconstructed_sentences, _ = gtos.generate(amr_graphs[:5])  # Test on first 5 AMRs\n",
    "for amr, recon_sent in zip(amr_graphs[:5], reconstructed_sentences):\n",
    "    print(f\"\\nAMR:\\n{amr}\\nReconstructed Sentence: {recon_sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### SpaCy AMR Extension ###\n",
      "\n",
      "Sentence: what are some updates about the stock market\n",
      "SpaCy AMR Graph:\n",
      "# ::snt what are some updates about the stock market\n",
      "(u / update-02\n",
      "      :ARG1 (m / market\n",
      "            :mod (s / stock))\n",
      "      :ARG2 (a / amr-unknown)\n",
      "      :quant (s2 / some))\n",
      "\n",
      "Sentence: definition of velocity\n",
      "SpaCy AMR Graph:\n",
      "# ::snt definition of velocity\n",
      "(d / define-01\n",
      "      :ARG1 (v / velocity))\n",
      "\n",
      "Sentence: please look up exchange between us and mexico\n",
      "SpaCy AMR Graph:\n",
      "# ::snt please look up exchange between us and mexico\n",
      "(l / look-up-05\n",
      "      :polite +\n",
      "      :mode imperative\n",
      "      :ARG0 (y / you)\n",
      "      :ARG1 (e / exchange-01\n",
      "            :ARG0 (w / we)\n",
      "            :ARG2 (c / country\n",
      "                  :name (n / name\n",
      "                        :op1 \"Mexico\"))))\n"
     ]
    }
   ],
   "source": [
    "# --- Test SpaCy + AMR ---\n",
    "print(\"\\n### SpaCy AMR Extension ###\")\n",
    "for sent in sentences[:3]:  # Test on first 3 sentences\n",
    "    doc = nlp(sent)\n",
    "    doc_graphs = doc._.to_amr()\n",
    "    for graph in doc_graphs:\n",
    "        print(f\"\\nSentence: {sent}\\nSpaCy AMR Graph:\\n{graph}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try to translate the dataset to Irish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import MarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1. Load Translation Model (English â†’ Irish)\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Helsinki-NLP/opus-mt-en-ga\"  # English to Irish\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2. Load JSONL Data\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/massive_amr.jsonl\"\n",
    "output_file = \"data/massive_amr_irish.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3. Translate Function\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, tokenizer, model):\n",
    "    \"\"\"Translates English text to Irish using MarianMT.\"\"\"\n",
    "    if not text.strip():\n",
    "        return text  # Skip empty strings\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    translated_tokens = model.generate(**inputs)\n",
    "    translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4. Translate Sentences\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in data:\n",
    "    entry[\"utt\"] = translate_text(entry[\"utt\"], tokenizer, model)\n",
    "    entry[\"annot_utt\"] = translate_text(entry[\"annot_utt\"], tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 5. Save Translated Data\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in data:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Translation complete! Saved as 'massive_amr_irish.jsonl'\n"
     ]
    }
   ],
   "source": [
    "print(\"âœ… Translation complete! Saved as 'massive_amr_irish.jsonl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try to train the AMR Parser on Welsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import amrlib\n",
    "print(amrlib.__version__)  # Should print the version number\n",
    "print(hasattr(amrlib, 'parse_string')) # Should print True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import amrlib\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainerCallback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/massive_amr_welsh.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_amr_data(file_path):\n",
    "    \"\"\"Loads a JSONL AMR dataset and removes entries with missing data.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "    # Filter out entries missing either the sentence or AMR\n",
    "    data = [entry for entry in data if entry.get(\"raw_amr\") and entry.get(\"utt\")]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_amr_data(file_path)\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences and AMR graphs\n",
    "sentences = [entry[\"utt\"] for entry in data]\n",
    "amrs = [entry[\"raw_amr\"] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test sets (90/10 then 10% of train for validation)\n",
    "train_sents, test_sents, train_amrs, test_amrs = train_test_split(sentences, amrs, test_size=0.1, random_state=42)\n",
    "train_sents, val_sents, train_amrs, val_amrs = train_test_split(train_sents, train_amrs, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Dataset format\n",
    "def create_dataset(sentences, amrs):\n",
    "    return Dataset.from_dict({\"sentence\": sentences, \"amr\": amrs})\n",
    "\n",
    "datasets = DatasetDict({\n",
    "    \"train\": create_dataset(train_sents, train_amrs),\n",
    "    \"validation\": create_dataset(val_sents, val_amrs),\n",
    "    \"test\": create_dataset(test_sents, test_amrs),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 3. Load Multilingual T5 Model (STOG & GTOS)\n",
    "# ==============================\n",
    "model_name = \"t5-small\"  # You can use a larger model if resources allow.\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # For T5 it's common to add a task prefix. Here we add \"parse: \" before the sentence.\n",
    "    inputs = [\"parse: \" + ex for ex in examples[\"sentence\"]]\n",
    "    targets = examples[\"amr\"]\n",
    "\n",
    "    # Tokenize inputs (source) and targets\n",
    "    model_inputs = tokenizer(inputs, max_length=256, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    # Replace padding token id's in labels with -100 so they are ignored by the loss function\n",
    "    labels[\"input_ids\"] = [\n",
    "        [l if l != tokenizer.pad_token_id else -100 for l in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e33c90f068f4dd9b45f339e3f6497fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1364 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f568b0c0d5774db09434d6fc79336562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded7f9a04c3a44caa76d2e5e9ae3ce78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply tokenization\n",
    "tokenized_datasets = datasets.map(preprocess_function, batched=True, remove_columns=[\"sentence\", \"amr\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stoic\\miniconda3\\envs\\llms_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 6. Define Optimized Training Arguments\n",
    "# ==============================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./amr_t5_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=50,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 5. Custom Callback for Logging and Visualization\n",
    "# ----------------------------\n",
    "class LossCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.eval_losses = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            if \"loss\" in logs:\n",
    "                self.losses.append((state.global_step, logs[\"loss\"]))\n",
    "            if \"eval_loss\" in logs:\n",
    "                self.eval_losses.append((state.global_step, logs[\"eval_loss\"]))\n",
    "\n",
    "    def plot_loss(self):\n",
    "        steps, losses = zip(*self.losses)\n",
    "        eval_steps, eval_losses = zip(*self.eval_losses)\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(steps, losses, label=\"Training Loss\", marker=\"o\")\n",
    "        plt.plot(eval_steps, eval_losses, label=\"Validation Loss\", marker=\"x\")\n",
    "        plt.xlabel(\"Training Steps\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training & Validation Loss Curve\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback = LossCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stoic\\AppData\\Local\\Temp\\ipykernel_20072\\1705589252.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 6. Initialize Trainer and Train the Model\n",
    "# ----------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[loss_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting T5 Training for AMR Parsing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1710' max='1710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1710/1710 08:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.038800</td>\n",
       "      <td>0.803618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.839300</td>\n",
       "      <td>0.687780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.714700</td>\n",
       "      <td>0.623573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.650600</td>\n",
       "      <td>0.588202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.597100</td>\n",
       "      <td>0.569191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.594500</td>\n",
       "      <td>0.556965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.572400</td>\n",
       "      <td>0.546731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.540736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.532300</td>\n",
       "      <td>0.534638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.494900</td>\n",
       "      <td>0.533489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1710, training_loss=0.7133498590592056, metrics={'train_runtime': 533.9115, 'train_samples_per_second': 25.547, 'train_steps_per_second': 3.203, 'total_flos': 923031086039040.0, 'train_loss': 0.7133498590592056, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Starting T5 Training for AMR Parsing...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 7. Plot Training Progress\n",
    "# ----------------------------\n",
    "loss_callback.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns: ['sentence', 'amr']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Columns:\", datasets[\"test\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns (after tokenization): ['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Columns (after tokenization):\", tokenized_datasets[\"test\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_amr_t5\\\\tokenizer_config.json',\n",
       " './fine_tuned_amr_t5\\\\special_tokens_map.json',\n",
       " './fine_tuned_amr_t5\\\\spiece.model',\n",
       " './fine_tuned_amr_t5\\\\added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 8. Save Fine-Tuned Model\n",
    "# ----------------------------\n",
    "model.save_pretrained(\"./fine_tuned_amr_t5\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_amr_t5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Smatch Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import smatch\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# â¿¡ Load Fine-Tuned T5 Model & Tokenizer\n",
    "# -----------------------------------\n",
    "model_path = \"./fine_tuned_amr_t5\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test Data\n",
    "file_path = \"data/massive_amr_welsh.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_amr_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "    return [entry for entry in data if entry.get(\"raw_amr\") and entry.get(\"utt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_amr_data(file_path)\n",
    "sentences = [entry[\"utt\"] for entry in data]\n",
    "gold_amrs = [entry[\"raw_amr\"] for entry in data]\n",
    "test_dataset = Dataset.from_dict({\"sentence\": sentences, \"amr\": gold_amrs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMR Cleaning Functions\n",
    "def balance_parentheses(amr_text):\n",
    "    \"\"\"Ensure AMR has balanced parentheses.\"\"\"\n",
    "    stack = []\n",
    "    for char in amr_text:\n",
    "        if char == \"(\":\n",
    "            stack.append(\"(\")\n",
    "        elif char == \")\":\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "            else:\n",
    "                return \"INVALID_AMR\"\n",
    "    return amr_text if not stack else \"INVALID_AMR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_duplicate_nodes(amr_text):\n",
    "    if not amr_text.strip():\n",
    "        return \"INVALID_AMR\"\n",
    "    \n",
    "    amr_text = balance_parentheses(amr_text)\n",
    "    if amr_text == \"INVALID_AMR\":\n",
    "        return \"INVALID_AMR\"\n",
    "    \n",
    "    used_vars = defaultdict(int)\n",
    "    renamed_vars = {}\n",
    "\n",
    "    def rename_variable(match):\n",
    "        var_name = match.group(1)\n",
    "        if var_name in used_vars:\n",
    "            new_var_name = f\"{var_name}_{used_vars[var_name]}\"\n",
    "            used_vars[var_name] += 1\n",
    "            renamed_vars[var_name] = new_var_name\n",
    "            return f\"({new_var_name} /\"\n",
    "        else:\n",
    "            used_vars[var_name] = 1\n",
    "            return f\"({var_name} /\"\n",
    "    \n",
    "    amr_text = re.sub(r\"\\((\\w+)\\s+/\", rename_variable, amr_text)\n",
    "    for old_var, new_var in renamed_vars.items():\n",
    "        amr_text = amr_text.replace(f\" {old_var} \", f\" {new_var} \")\n",
    "    \n",
    "    return amr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_amr_predictions(model, tokenizer, test_dataset, max_samples=100):\n",
    "    predictions = []\n",
    "    for i, example in enumerate(test_dataset):\n",
    "        if i >= max_samples:\n",
    "            break\n",
    "        \n",
    "        input_text = \"parse: \" + example[\"sentence\"]\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(input_ids, max_length=512)\n",
    "        \n",
    "        predicted_amr = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        predicted_amr = fix_duplicate_nodes(predicted_amr)\n",
    "        gold_amr = fix_duplicate_nodes(example[\"amr\"])\n",
    "        predictions.append((gold_amr, predicted_amr))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_amr(amr):\n",
    "    return amr.count('/') > 0 and amr != \"INVALID_AMR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_smatch(gold_amrs, predicted_amrs):\n",
    "    total_precision, total_recall, total_f1 = 0, 0, 0\n",
    "    valid_samples = 0\n",
    "\n",
    "    for i, (gold, pred) in enumerate(zip(gold_amrs, predicted_amrs)):\n",
    "        try:\n",
    "            if not is_valid_amr(pred) or not is_valid_amr(gold):\n",
    "                print(f\"Skipping sample {i} due to invalid AMR\")\n",
    "                continue\n",
    "            \n",
    "            precision, recall, f_score = smatch.get_amr_match(str(gold), str(pred))\n",
    "            total_precision += precision\n",
    "            total_recall += recall\n",
    "            total_f1 += f_score\n",
    "            valid_samples += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Smatch calculation for sample {i}: {e}\")\n",
    "            print(f\"Gold AMR: {gold}\")\n",
    "            print(f\"Predicted AMR: {pred}\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    if valid_samples == 0:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    return total_precision / valid_samples, total_recall / valid_samples, total_f1 / valid_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping sample 3 due to invalid AMR\n",
      "Skipping sample 7 due to invalid AMR\n",
      "Skipping sample 12 due to invalid AMR\n",
      "Skipping sample 14 due to invalid AMR\n",
      "Skipping sample 28 due to invalid AMR\n",
      "Skipping sample 50 due to invalid AMR\n",
      "Skipping sample 55 due to invalid AMR\n",
      "Skipping sample 64 due to invalid AMR\n",
      "Skipping sample 68 due to invalid AMR\n",
      "Skipping sample 85 due to invalid AMR\n",
      "Skipping sample 91 due to invalid AMR\n",
      "Skipping sample 92 due to invalid AMR\n",
      "Skipping sample 95 due to invalid AMR\n"
     ]
    }
   ],
   "source": [
    "# Generate and Evaluate AMRs\n",
    "predictions = generate_amr_predictions(model, tokenizer, test_dataset)\n",
    "gold_amrs = [gold for gold, _ in predictions if gold is not None]\n",
    "predicted_amrs = [pred for _, pred in predictions if pred is not None]\n",
    "precision, recall, f1 = compute_smatch(gold_amrs, predicted_amrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smatch Score - Precision: 4.9540, Recall: 11.3103, F1: 13.1379\n"
     ]
    }
   ],
   "source": [
    "# Display Results\n",
    "print(f\"Smatch Score - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Dataset for Corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"data/massive_amr_welsh.jsonl\"\n",
    "valid_entries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            entry = json.loads(line)\n",
    "            if \"utt\" in entry and \"raw_amr\" in entry and isinstance(entry[\"utt\"], str) and isinstance(entry[\"raw_amr\"], str):\n",
    "                valid_entries.append(entry)\n",
    "            else:\n",
    "                print(f\"âŒ Corrupt entry found and skipped: {entry}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"âŒ JSON Decode Error in line: {line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Valid samples: 1685\n"
     ]
    }
   ],
   "source": [
    "print(f\"âœ… Valid samples: {len(valid_entries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned dataset saved as 'data/cleaned_amr_welsh.jsonl'\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "with open(\"data/cleaned_amr_welsh.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in valid_entries:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(\"âœ… Cleaned dataset saved as 'data/cleaned_amr_welsh.jsonl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
