{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import amrlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ::snt This is a test of the system.\n",
      "(t / test-01\n",
      "      :ARG1 (s / system)\n",
      "      :domain (t2 / this))\n",
      "# ::snt This is a second sentence.\n",
      "(s / sentence\n",
      "      :ord (o / ordinal-entity\n",
      "            :value 2)\n",
      "      :domain (t / this))\n"
     ]
    }
   ],
   "source": [
    "stog = amrlib.load_stog_model()\n",
    "graphs = stog.parse_sents(['This is a test of the system.', 'This is a second sentence.'])\n",
    "for graph in graphs:\n",
    "    print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is system testing.\n",
      "This is the second sentence.\n"
     ]
    }
   ],
   "source": [
    "gtos = amrlib.load_gtos_model()\n",
    "sents, _ = gtos.generate(graphs)\n",
    "for sent in sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ::snt This is a test of the SpaCy extension.\n",
      "(t / test-01\n",
      "      :ARG1 (e / extend-01\n",
      "            :ARG1 (p / product\n",
      "                  :name (n / name\n",
      "                        :op1 \"SpaCy\")))\n",
      "      :domain (t2 / this))\n",
      "# ::snt The test has multiple sentences.\n",
      "(h / have-03\n",
      "      :ARG0 (t / test)\n",
      "      :ARG1 (s / sentence\n",
      "            :quant (m / multiple)))\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "amrlib.setup_spacy_extension()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('This is a test of the SpaCy extension. The test has multiple sentences.')\n",
    "graphs = doc._.to_amr()\n",
    "for graph in graphs:\n",
    "    print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import amrlib\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "amrlib.setup_spacy_extension()\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your JSONL file\n",
    "file_path = \"data/massive_amr.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSONL file\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = [json.loads(line) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences and AMR graphs\n",
    "sentences = [entry[\"utt\"] for entry in data]\n",
    "amr_graphs = [entry[\"raw_amr\"] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### STOG: Sentences to AMR ###\n",
      "\n",
      "Sentence: what are some updates about the stock market\n",
      "AMR Graph:\n",
      "# ::snt what are some updates about the stock market\n",
      "(u / update-02\n",
      "      :ARG1 (m / market\n",
      "            :mod (s / stock))\n",
      "      :ARG2 (a / amr-unknown)\n",
      "      :quant (s2 / some))\n",
      "\n",
      "Sentence: definition of velocity\n",
      "AMR Graph:\n",
      "# ::snt definition of velocity\n",
      "(d / define-01\n",
      "      :ARG1 (v / velocity))\n",
      "\n",
      "Sentence: please look up exchange between us and mexico\n",
      "AMR Graph:\n",
      "# ::snt please look up exchange between us and mexico\n",
      "(l / look-up-05\n",
      "      :polite +\n",
      "      :mode imperative\n",
      "      :ARG0 (y / you)\n",
      "      :ARG1 (e / exchange-01\n",
      "            :ARG0 (w / we)\n",
      "            :ARG2 (c / country\n",
      "                  :name (n / name\n",
      "                        :op1 \"Mexico\"))))\n",
      "\n",
      "Sentence: can you describe to me what a pineapple looks like\n",
      "AMR Graph:\n",
      "# ::snt can you describe to me what a pineapple looks like\n",
      "(p / possible-01\n",
      "      :polarity (a / amr-unknown)\n",
      "      :ARG1 (d / describe-01\n",
      "            :ARG0 (y / you)\n",
      "            :ARG1 (l / look-02\n",
      "                  :ARG0 (p2 / pineapple)\n",
      "                  :ARG1 (t / thing))\n",
      "            :ARG2 (ii / i)))\n",
      "\n",
      "Sentence: what is the dollar against the pound\n",
      "AMR Graph:\n",
      "# ::snt what is the dollar against the pound\n",
      "(d / dollar\n",
      "      :prep-against (p / pound)\n",
      "      :domain (a / amr-unknown))\n"
     ]
    }
   ],
   "source": [
    "# --- Test STOG: Convert Sentences to AMR ---\n",
    "print(\"\\n### STOG: Sentences to AMR ###\")\n",
    "parsed_graphs = stog.parse_sents(sentences[:5])  # Test on first 5 sentences\n",
    "for sent, graph in zip(sentences[:5], parsed_graphs):\n",
    "    print(f\"\\nSentence: {sent}\\nAMR Graph:\\n{graph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### GTOS: AMR to Sentences ###\n",
      "\n",
      "AMR:\n",
      "(u / update-02\n",
      "      :ARG2 (a / amr-unknown)\n",
      "      :topic (m / market-01\n",
      "            :ARG1 (s / stock))\n",
      "      :mod (s2 / some))\n",
      "Reconstructed Sentence: What are some stock market updates?\n",
      "\n",
      "AMR:\n",
      "(d / define-01\n",
      "      :ARG1 (v / velocity)\n",
      "      :ARG2 (a / amr-unknown))\n",
      "Reconstructed Sentence: What is the definition of velocity?\n",
      "\n",
      "AMR:\n",
      "(l / look-up-05 :mode imperative :polite +\n",
      "      :ARG0 (y / you)\n",
      "      :ARG1 (e / exchange-01\n",
      "            :ARG1 (c / currency\n",
      "                  :mod (c3 / country :name (n / name :op1 \"us\")))\n",
      "            :ARG3 (c2 / currency\n",
      "                  :mod (c4 / country :name (n2 / name :op1 \"mexico\")))))\n",
      "Reconstructed Sentence: Please look up exchange rates between US and Mexican currency.\n",
      "\n",
      "AMR:\n",
      "(d / describe-01 :mode imperative :polite +\n",
      "      :ARG0 (y / you)\n",
      "      :ARG1 (t / thing\n",
      "            :ARG1-of (l / look-02\n",
      "                  :ARG0 (f / food-dish :name (n / name :op1 \"pineapple\")))))\n",
      "Reconstructed Sentence: Please describe how the pineapple looks.\n",
      "\n",
      "AMR:\n",
      "(h / have-quant-91\n",
      "      :ARG1 (c / currency :name (n / name :op1 \"dollar\"))\n",
      "      :ARG2 (a / amr-unknown)\n",
      "      :ARG4 (c2 / currency :name (n2 / name :op1 \"pound\")))\n",
      "Reconstructed Sentence: How many are dollars compared to pounds?\n"
     ]
    }
   ],
   "source": [
    "# --- Test GTOS: Convert AMR to Sentences ---\n",
    "print(\"\\n### GTOS: AMR to Sentences ###\")\n",
    "reconstructed_sentences, _ = gtos.generate(amr_graphs[:5])  # Test on first 5 AMRs\n",
    "for amr, recon_sent in zip(amr_graphs[:5], reconstructed_sentences):\n",
    "    print(f\"\\nAMR:\\n{amr}\\nReconstructed Sentence: {recon_sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### SpaCy AMR Extension ###\n",
      "\n",
      "Sentence: what are some updates about the stock market\n",
      "SpaCy AMR Graph:\n",
      "# ::snt what are some updates about the stock market\n",
      "(u / update-02\n",
      "      :ARG1 (m / market\n",
      "            :mod (s / stock))\n",
      "      :ARG2 (a / amr-unknown)\n",
      "      :quant (s2 / some))\n",
      "\n",
      "Sentence: definition of velocity\n",
      "SpaCy AMR Graph:\n",
      "# ::snt definition of velocity\n",
      "(d / define-01\n",
      "      :ARG1 (v / velocity))\n",
      "\n",
      "Sentence: please look up exchange between us and mexico\n",
      "SpaCy AMR Graph:\n",
      "# ::snt please look up exchange between us and mexico\n",
      "(l / look-up-05\n",
      "      :polite +\n",
      "      :mode imperative\n",
      "      :ARG0 (y / you)\n",
      "      :ARG1 (e / exchange-01\n",
      "            :ARG0 (w / we)\n",
      "            :ARG2 (c / country\n",
      "                  :name (n / name\n",
      "                        :op1 \"Mexico\"))))\n"
     ]
    }
   ],
   "source": [
    "# --- Test SpaCy + AMR ---\n",
    "print(\"\\n### SpaCy AMR Extension ###\")\n",
    "for sent in sentences[:3]:  # Test on first 3 sentences\n",
    "    doc = nlp(sent)\n",
    "    doc_graphs = doc._.to_amr()\n",
    "    for graph in doc_graphs:\n",
    "        print(f\"\\nSentence: {sent}\\nSpaCy AMR Graph:\\n{graph}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try to translate the dataset to Irish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import MarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1. Load Translation Model (English → Irish)\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Helsinki-NLP/opus-mt-en-ga\"  # English to Irish\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2. Load JSONL Data\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/massive_amr.jsonl\"\n",
    "output_file = \"data/massive_amr_irish.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3. Translate Function\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, tokenizer, model):\n",
    "    \"\"\"Translates English text to Irish using MarianMT.\"\"\"\n",
    "    if not text.strip():\n",
    "        return text  # Skip empty strings\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    translated_tokens = model.generate(**inputs)\n",
    "    translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4. Translate Sentences\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in data:\n",
    "    entry[\"utt\"] = translate_text(entry[\"utt\"], tokenizer, model)\n",
    "    entry[\"annot_utt\"] = translate_text(entry[\"annot_utt\"], tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 5. Save Translated Data\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in data:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Translation complete! Saved as 'massive_amr_irish.jsonl'\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Translation complete! Saved as 'massive_amr_irish.jsonl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
